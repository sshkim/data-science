{"cells":[{"cell_type":"markdown","metadata":{},"source":["### This is a very simple example on how to use PySpark ML on kaggle's titanic dataset.\n\nProblem statement and dataset can be found here https://www.kaggle.com/c/titanic"]},{"cell_type":"markdown","metadata":{},"source":["### Prerequisites:\n  * Basics understand of python https://www.kaggle.com/learn/python\n  * Pandas https://www.kaggle.com/learn/pandas\n  * Machine learning https://www.kaggle.com/learn/machine-learning\n\n  * Apache Spark \n\n      https://docs.databricks.com/spark/latest/gentle-introduction/gentle-intro.html\n      \n      https://docs.databricks.com/spark/latest/gentle-introduction/gentle-intro.html#gentle-introduction-to-apache-spark\n      \n      https://docs.databricks.com/spark/latest/gentle-introduction/for-data-scientists.html"]},{"cell_type":"markdown","metadata":{},"source":["#### Importing the necessary libraries"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import QuantileDiscretizer\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Starting Point: SparkSession"]},{"cell_type":"markdown","metadata":{},"source":["The entry point into all functionality in Spark is the SparkSession class. To create a basic SparkSession, just use SparkSession.builder"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["spark = SparkSession \\\n    .builder \\\n    .appName(\"Spark ML example on titanic data \") \\\n    .getOrCreate()"]},{"cell_type":"markdown","metadata":{},"source":["Next, we have to import the dataset. In this file, I am importing dataset from S3(https://docs.databricks.com/spark/latest/data-sources/aws/amazon-s3.html).\n\nYou can can directly upload dataset to databricks cloud(https://docs.databricks.com/user-guide/importing-data.html#import-data)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["s3_bucket_path = \"/mnt/lp-dataset/titanic/train.csv\""]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df = spark.read.csv(s3_bucket_path,header = 'True',inferSchema='True')"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["passengers_count = titanic_df.count()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">891\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["print(passengers_count)"]},{"cell_type":"markdown","metadata":{},"source":["Lets  view few rows"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nPassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 5 rows\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.show(5)"]},{"cell_type":"markdown","metadata":{},"source":["Summary of data"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\nsummary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n    min|                1|                  0|                 1|&quot;Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.describe().show()"]},{"cell_type":"markdown","metadata":{},"source":["Let's see Schema of our dataset"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- PassengerId: integer (nullable = true)\n-- Survived: integer (nullable = true)\n-- Pclass: integer (nullable = true)\n-- Name: string (nullable = true)\n-- Sex: string (nullable = true)\n-- Age: double (nullable = true)\n-- SibSp: integer (nullable = true)\n-- Parch: integer (nullable = true)\n-- Ticket: string (nullable = true)\n-- Fare: double (nullable = true)\n-- Cabin: string (nullable = true)\n-- Embarked: string (nullable = true)\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["Let's select few features"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+------+--------+\nSurvived|Pclass|Embarked|\n+--------+------+--------+\n       0|     3|       S|\n       1|     1|       C|\n       1|     3|       S|\n       1|     1|       S|\n       0|     3|       S|\n       0|     3|       Q|\n       0|     1|       S|\n       0|     3|       S|\n       1|     3|       S|\n       1|     2|       C|\n       1|     3|       S|\n       1|     1|       S|\n       0|     3|       S|\n       0|     3|       S|\n       0|     3|       S|\n       1|     2|       S|\n       0|     3|       Q|\n       1|     2|       S|\n       0|     3|       S|\n       1|     3|       C|\n+--------+------+--------+\nonly showing top 20 rows\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.select(\"Survived\",\"Pclass\",\"Embarked\").show()"]},{"cell_type":"markdown","metadata":{},"source":["### Let's do some simple exploratory data analysis (EDA)"]},{"cell_type":"markdown","metadata":{},"source":["How many Passengers Survived ?"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-----+\nSurvived|count|\n+--------+-----+\n       1|  342|\n       0|  549|\n+--------+-----+\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.groupBy(\"Survived\").count().show()"]},{"cell_type":"markdown","metadata":{},"source":["Out of 891 passengers in dataset, only around 342 survived."]},{"cell_type":"markdown","metadata":{},"source":["We need to dig down more to get better insights from the data and see which categories of the passengers did survive and who didn't. We will try to check the survival rate by using the different features of the dataset. Some of the features being Sex, Port Of Embarcation, Age,etc."]},{"cell_type":"markdown","metadata":{},"source":["Lets check survival rate with Sex"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+--------+-----+\n   Sex|Survived|count|\n+------+--------+-----+\n  male|       0|  468|\nfemale|       1|  233|\nfemale|       0|   81|\n  male|       1|  109|\n+------+--------+-----+\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.groupBy(\"Sex\",\"Survived\").count().show()"]},{"cell_type":"markdown","metadata":{},"source":["This looks interesting. The number of men on the ship is lot more than the number of women. Still the number of women saved is almost twice the number of males saved."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+--------+-----+\nPclass|Survived|count|\n+------+--------+-----+\n     1|       0|   80|\n     3|       1|  119|\n     1|       1|  136|\n     2|       1|   87|\n     2|       0|   97|\n     3|       0|  372|\n+------+--------+-----+\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.groupBy(\"Pclass\",\"Survived\").count().show()"]},{"cell_type":"markdown","metadata":{},"source":["We can clearly see that Passenegers Of Pclass 1 were given a very high priority while rescue. Even though the the number of Passengers in Pclass 3 were a lot higher, still the number of survival from them is very low."]},{"cell_type":"markdown","metadata":{},"source":["#### Checking Null values"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["# This function use to print feature with null values and null count \ndef null_value_count(df):\n  null_columns_counts = []\n  numRows = df.count()\n  for k in df.columns:\n    nullRows = df.where(col(k).isNull()).count()\n    if(nullRows > 0):\n      temp = k,nullRows\n      null_columns_counts.append(temp)\n  return(null_columns_counts)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["# Calling function\nnull_columns_count_list = null_value_count(titanic_df)\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------+-----------------+\nColumn_With_Null_Value|Null_Values_Count|\n+----------------------+-----------------+\n                   Age|              177|\n                 Cabin|              687|\n              Embarked|                2|\n+----------------------+-----------------+\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()"]},{"cell_type":"markdown","metadata":{},"source":["Age feature has 177 null values."]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">29.6991176471\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["mean_age = titanic_df.select(mean('Age')).collect()[0][0]\nprint(mean_age)"]},{"cell_type":"markdown","metadata":{},"source":["To replace these NaN values, we can assign them the mean age of the dataset.But the problem is, there were many people with many different ages. We just cant assign a 4 year kid with the mean age that is 29 years."]},{"cell_type":"markdown","metadata":{},"source":["we can check the Name feature. Looking upon the feature, we can see that the names have a salutation like Mr or Mrs. Thus we can assign the mean values of Mr and Mrs to the respective groups"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df = titanic_df.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))"]},{"cell_type":"markdown","metadata":{},"source":["Using the Regex \"\"[A-Za-z]+).\" we extract the initials from the Name. It looks for strings which lie between A-Z or a-z and followed by a .(dot)."]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\nPassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Initial|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\n          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Mr|\n          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Mrs|\n          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|   Miss|\n          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|    Mrs|\n          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|     Mr|\n          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|     Mr|\n          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|     Mr|\n          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S| Master|\n          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|    Mrs|\n         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|    Mrs|\n         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|   Miss|\n         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|   Miss|\n         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|     Mr|\n         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|     Mr|\n         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|   Miss|\n         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|    Mrs|\n         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q| Master|\n         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|     Mr|\n         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|    Mrs|\n         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|    Mrs|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\nonly showing top 20 rows\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.show()"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+\n Initial|\n+--------+\n     Don|\n    Miss|\nCountess|\n     Col|\n     Rev|\n    Lady|\n  Master|\n     Mme|\n    Capt|\n      Mr|\n      Dr|\n     Mrs|\n     Sir|\nJonkheer|\n    Mlle|\n   Major|\n      Ms|\n+--------+\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.select(\"Initial\").distinct().show()\n"]},{"cell_type":"markdown","metadata":{},"source":["There are some misspelled Initials like Mlle or Mme that stand for Miss. I will replace them with Miss and same thing for other values."]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df = titanic_df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n               ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+\nInitial|\n+-------+\n   Miss|\n  Other|\n Master|\n     Mr|\n    Mrs|\n+-------+\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.select(\"Initial\").distinct().show()\n"]},{"cell_type":"markdown","metadata":{},"source":["lets check the average age by Initials"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">360</span><span class=\"ansired\">]: </span>\n[Row(Initial=u&apos;Miss&apos;, avg(Age)=21.86),\n Row(Initial=u&apos;Other&apos;, avg(Age)=45.888888888888886),\n Row(Initial=u&apos;Master&apos;, avg(Age)=4.574166666666667),\n Row(Initial=u&apos;Mr&apos;, avg(Age)=32.73960880195599),\n Row(Initial=u&apos;Mrs&apos;, avg(Age)=35.981818181818184)]\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.groupby('Initial').avg('Age').collect()"]},{"cell_type":"markdown","metadata":{},"source":["Let's impute missing values in age feature based on average age of Initials"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Miss\") & (titanic_df[\"Age\"].isNull()), 22).otherwise(titanic_df[\"Age\"]))\ntitanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Other\") & (titanic_df[\"Age\"].isNull()), 46).otherwise(titanic_df[\"Age\"]))\ntitanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Master\") & (titanic_df[\"Age\"].isNull()), 5).otherwise(titanic_df[\"Age\"]))\ntitanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mr\") & (titanic_df[\"Age\"].isNull()), 33).otherwise(titanic_df[\"Age\"]))\ntitanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mrs\") & (titanic_df[\"Age\"].isNull()), 36).otherwise(titanic_df[\"Age\"]))\n"]},{"cell_type":"markdown","metadata":{},"source":["Check the imputation"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+\nInitial|\n+-------+\n     Mr|\n     Mr|\n     Mr|\n+-------+\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.filter(titanic_df.Age==46).select(\"Initial\").show()\n"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+\n Age|\n+----+\n22.0|\n38.0|\n26.0|\n35.0|\n35.0|\n33.0|\n54.0|\n 2.0|\n27.0|\n14.0|\n 4.0|\n58.0|\n20.0|\n39.0|\n14.0|\n55.0|\n 2.0|\n33.0|\n31.0|\n36.0|\n+----+\nonly showing top 20 rows\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.select(\"Age\").show()"]},{"cell_type":"markdown","metadata":{},"source":["Embarked feature has only two missining values. Let's check values within Embarked"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-----+\nEmbarked|count|\n+--------+-----+\n       Q|   77|\n    null|    2|\n       C|  168|\n       S|  644|\n+--------+-----+\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.groupBy(\"Embarked\").count().show()"]},{"cell_type":"markdown","metadata":{},"source":["Majority Passengers boarded from \"S\". We can impute with \"S\""]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df = titanic_df.na.fill({\"Embarked\" : 'S'})\n"]},{"cell_type":"markdown","metadata":{},"source":["We can drop Cabin features as it has lots of null values"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df = titanic_df.drop(\"Cabin\")"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- PassengerId: integer (nullable = true)\n-- Survived: integer (nullable = true)\n-- Pclass: integer (nullable = true)\n-- Name: string (nullable = true)\n-- Sex: string (nullable = true)\n-- Age: double (nullable = true)\n-- SibSp: integer (nullable = true)\n-- Parch: integer (nullable = true)\n-- Ticket: string (nullable = true)\n-- Fare: double (nullable = true)\n-- Embarked: string (nullable = false)\n-- Initial: string (nullable = true)\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["We can create a new feature called \"Family_size\" and \"Alone\" and analyse it. This feature is the summation of Parch(parents/children) and SibSp(siblings/spouses). It gives us a combined data so that we can check if survival rate have anything to do with family size of the passengers"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df = titanic_df.withColumn(\"Family_Size\",col('SibSp')+col('Parch'))"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+-----+\nFamily_Size|count|\n+-----------+-----+\n          1|  161|\n          6|   12|\n          3|   29|\n          5|   22|\n          4|   15|\n          7|    6|\n         10|    7|\n          2|  102|\n          0|  537|\n+-----------+-----+\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.groupBy(\"Family_Size\").count().show()"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df = titanic_df.withColumn('Alone',lit(0))\n"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df = titanic_df.withColumn(\"Alone\",when(titanic_df[\"Family_Size\"] == 0, 1).otherwise(titanic_df[\"Alone\"]))"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">375</span><span class=\"ansired\">]: </span>\n[&apos;PassengerId&apos;,\n &apos;Survived&apos;,\n &apos;Pclass&apos;,\n &apos;Name&apos;,\n &apos;Sex&apos;,\n &apos;Age&apos;,\n &apos;SibSp&apos;,\n &apos;Parch&apos;,\n &apos;Ticket&apos;,\n &apos;Fare&apos;,\n &apos;Embarked&apos;,\n &apos;Initial&apos;,\n &apos;Family_Size&apos;,\n &apos;Alone&apos;]\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.columns"]},{"cell_type":"markdown","metadata":{},"source":["Lets convert Sex, Embarked & Initial columns from string to number using StringIndexer"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(titanic_df) for column in [\"Sex\",\"Embarked\",\"Initial\"]]\npipeline = Pipeline(stages=indexers)\ntitanic_df = pipeline.fit(titanic_df).transform(titanic_df)"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+-----------+-----+---------+--------------+-------------+\nPassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|Initial|Family_Size|Alone|Sex_index|Embarked_index|Initial_index|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+-----------+-----+---------+--------------+-------------+\n          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|     Mr|          1|    0|      0.0|           0.0|          0.0|\n          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|    Mrs|          1|    0|      1.0|           1.0|          2.0|\n          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|   Miss|          0|    1|      1.0|           0.0|          1.0|\n          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|    Mrs|          1|    0|      1.0|           0.0|          2.0|\n          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|     Mr|          0|    1|      0.0|           0.0|          0.0|\n          6|       0|     3|    Moran, Mr. James|  male|33.0|    0|    0|          330877| 8.4583|       Q|     Mr|          0|    1|      0.0|           2.0|          0.0|\n          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|     Mr|          0|    1|      0.0|           0.0|          0.0|\n          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S| Master|          4|    0|      0.0|           0.0|          3.0|\n          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|    Mrs|          2|    0|      1.0|           0.0|          2.0|\n         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|    Mrs|          1|    0|      1.0|           1.0|          2.0|\n         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|       S|   Miss|          2|    0|      1.0|           0.0|          1.0|\n         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|       S|   Miss|          0|    1|      1.0|           0.0|          1.0|\n         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|       S|     Mr|          0|    1|      0.0|           0.0|          0.0|\n         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|       S|     Mr|          6|    0|      0.0|           0.0|          0.0|\n         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|       S|   Miss|          0|    1|      1.0|           0.0|          1.0|\n         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|       S|    Mrs|          0|    1|      1.0|           0.0|          2.0|\n         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|       Q| Master|          5|    0|      0.0|           2.0|          3.0|\n         18|       1|     2|Williams, Mr. Cha...|  male|33.0|    0|    0|          244373|   13.0|       S|     Mr|          0|    1|      0.0|           0.0|          0.0|\n         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|       S|    Mrs|          1|    0|      1.0|           0.0|          2.0|\n         20|       1|     3|Masselmani, Mrs. ...|female|36.0|    0|    0|            2649|  7.225|       C|    Mrs|          0|    1|      1.0|           1.0|          2.0|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+-----------+-----+---------+--------------+-------------+\nonly showing top 20 rows\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.show()"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- PassengerId: integer (nullable = true)\n-- Survived: integer (nullable = true)\n-- Pclass: integer (nullable = true)\n-- Name: string (nullable = true)\n-- Sex: string (nullable = true)\n-- Age: double (nullable = true)\n-- SibSp: integer (nullable = true)\n-- Parch: integer (nullable = true)\n-- Ticket: string (nullable = true)\n-- Fare: double (nullable = true)\n-- Embarked: string (nullable = false)\n-- Initial: string (nullable = true)\n-- Family_Size: integer (nullable = true)\n-- Alone: integer (nullable = false)\n-- Sex_index: double (nullable = false)\n-- Embarked_index: double (nullable = false)\n-- Initial_index: double (nullable = false)\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["Drop columns which are not required"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df = titanic_df.drop(\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\",\"Sex\",\"Initial\")"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+\nSurvived|Pclass| Age|SibSp|Parch|   Fare|Family_Size|Alone|Sex_index|Embarked_index|Initial_index|\n+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+\n       0|     3|22.0|    1|    0|   7.25|          1|    0|      0.0|           0.0|          0.0|\n       1|     1|38.0|    1|    0|71.2833|          1|    0|      1.0|           1.0|          2.0|\n       1|     3|26.0|    0|    0|  7.925|          0|    1|      1.0|           0.0|          1.0|\n       1|     1|35.0|    1|    0|   53.1|          1|    0|      1.0|           0.0|          2.0|\n       0|     3|35.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|          0.0|\n       0|     3|33.0|    0|    0| 8.4583|          0|    1|      0.0|           2.0|          0.0|\n       0|     1|54.0|    0|    0|51.8625|          0|    1|      0.0|           0.0|          0.0|\n       0|     3| 2.0|    3|    1| 21.075|          4|    0|      0.0|           0.0|          3.0|\n       1|     3|27.0|    0|    2|11.1333|          2|    0|      1.0|           0.0|          2.0|\n       1|     2|14.0|    1|    0|30.0708|          1|    0|      1.0|           1.0|          2.0|\n       1|     3| 4.0|    1|    1|   16.7|          2|    0|      1.0|           0.0|          1.0|\n       1|     1|58.0|    0|    0|  26.55|          0|    1|      1.0|           0.0|          1.0|\n       0|     3|20.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|          0.0|\n       0|     3|39.0|    1|    5| 31.275|          6|    0|      0.0|           0.0|          0.0|\n       0|     3|14.0|    0|    0| 7.8542|          0|    1|      1.0|           0.0|          1.0|\n       1|     2|55.0|    0|    0|   16.0|          0|    1|      1.0|           0.0|          2.0|\n       0|     3| 2.0|    4|    1| 29.125|          5|    0|      0.0|           2.0|          3.0|\n       1|     2|33.0|    0|    0|   13.0|          0|    1|      0.0|           0.0|          0.0|\n       0|     3|31.0|    1|    0|   18.0|          1|    0|      1.0|           0.0|          2.0|\n       1|     3|36.0|    0|    0|  7.225|          0|    1|      1.0|           1.0|          2.0|\n+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+\nonly showing top 20 rows\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["titanic_df.show()"]},{"cell_type":"markdown","metadata":{},"source":["Let's put all features into a vector"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["feature = VectorAssembler(inputCols=titanic_df.columns[1:],outputCol=\"features\")\nfeature_vector= feature.transform(titanic_df)"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+--------------------+\nSurvived|Pclass| Age|SibSp|Parch|   Fare|Family_Size|Alone|Sex_index|Embarked_index|Initial_index|            features|\n+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+--------------------+\n       0|     3|22.0|    1|    0|   7.25|          1|    0|      0.0|           0.0|          0.0|(10,[0,1,2,4,5],[...|\n       1|     1|38.0|    1|    0|71.2833|          1|    0|      1.0|           1.0|          2.0|[1.0,38.0,1.0,0.0...|\n       1|     3|26.0|    0|    0|  7.925|          0|    1|      1.0|           0.0|          1.0|[3.0,26.0,0.0,0.0...|\n       1|     1|35.0|    1|    0|   53.1|          1|    0|      1.0|           0.0|          2.0|[1.0,35.0,1.0,0.0...|\n       0|     3|35.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|          0.0|(10,[0,1,4,6],[3....|\n       0|     3|33.0|    0|    0| 8.4583|          0|    1|      0.0|           2.0|          0.0|(10,[0,1,4,6,8],[...|\n       0|     1|54.0|    0|    0|51.8625|          0|    1|      0.0|           0.0|          0.0|(10,[0,1,4,6],[1....|\n       0|     3| 2.0|    3|    1| 21.075|          4|    0|      0.0|           0.0|          3.0|[3.0,2.0,3.0,1.0,...|\n       1|     3|27.0|    0|    2|11.1333|          2|    0|      1.0|           0.0|          2.0|[3.0,27.0,0.0,2.0...|\n       1|     2|14.0|    1|    0|30.0708|          1|    0|      1.0|           1.0|          2.0|[2.0,14.0,1.0,0.0...|\n       1|     3| 4.0|    1|    1|   16.7|          2|    0|      1.0|           0.0|          1.0|[3.0,4.0,1.0,1.0,...|\n       1|     1|58.0|    0|    0|  26.55|          0|    1|      1.0|           0.0|          1.0|[1.0,58.0,0.0,0.0...|\n       0|     3|20.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|          0.0|(10,[0,1,4,6],[3....|\n       0|     3|39.0|    1|    5| 31.275|          6|    0|      0.0|           0.0|          0.0|[3.0,39.0,1.0,5.0...|\n       0|     3|14.0|    0|    0| 7.8542|          0|    1|      1.0|           0.0|          1.0|[3.0,14.0,0.0,0.0...|\n       1|     2|55.0|    0|    0|   16.0|          0|    1|      1.0|           0.0|          2.0|[2.0,55.0,0.0,0.0...|\n       0|     3| 2.0|    4|    1| 29.125|          5|    0|      0.0|           2.0|          3.0|[3.0,2.0,4.0,1.0,...|\n       1|     2|33.0|    0|    0|   13.0|          0|    1|      0.0|           0.0|          0.0|(10,[0,1,4,6],[2....|\n       0|     3|31.0|    1|    0|   18.0|          1|    0|      1.0|           0.0|          2.0|[3.0,31.0,1.0,0.0...|\n       1|     3|36.0|    0|    0|  7.225|          0|    1|      1.0|           1.0|          2.0|[3.0,36.0,0.0,0.0...|\n+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+--------------------+\nonly showing top 20 rows\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["feature_vector.show()"]},{"cell_type":"markdown","metadata":{},"source":["Now that the data is all set, let's split it into training and test. I'll be using a 80%, 80% split."]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["(trainingData, testData) = feature_vector.randomSplit([0.8, 0.2],seed = 11)"]},{"cell_type":"markdown","metadata":{},"source":["### Modelling"]},{"cell_type":"markdown","metadata":{},"source":["Here is the list of few Classification Algorithms from Spark ML \n\nLogisticRegression\n\nDecisionTreeClassifier\n\nRandomForestClassifier\n\nGradient-boosted tree classifier\n\nNaiveBayes\n\nSupport Vector Machine"]},{"cell_type":"markdown","metadata":{},"source":["LogisticRegression"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+--------+--------------------+\nprediction|Survived|            features|\n+----------+--------+--------------------+\n       0.0|       0|[1.0,19.0,3.0,2.0...|\n       1.0|       0|[1.0,27.0,0.0,2.0...|\n       0.0|       0|(10,[0,1,4,6],[1....|\n       1.0|       0|[1.0,28.0,1.0,0.0...|\n       0.0|       0|(10,[0,1,4,6],[1....|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       1.0|       0|(10,[0,1,3,4,5],[...|\n       0.0|       0|(10,[0,1,6],[1.0,...|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|[1.0,51.0,0.0,1.0...|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,4,6],[2....|\n       0.0|       0|(10,[0,1,4,6],[2....|\n       0.0|       0|(10,[0,1,4,6],[2....|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|(10,[0,1,4,6],[2....|\n+----------+--------+--------------------+\nonly showing top 20 rows\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(labelCol=\"Survived\", featuresCol=\"features\")\n#Training algo\nlrModel = lr.fit(trainingData)\nlr_prediction = lrModel.transform(testData)\nlr_prediction.select(\"prediction\", \"Survived\", \"features\").show()\nevaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate how well is LogisticRegression doing"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of LogisticRegression is = 0.836257\nTest Error of LogisticRegression = 0.163743 \n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["lr_accuracy = evaluator.evaluate(lr_prediction)\nprint(\"Accuracy of LogisticRegression is = %g\"% (lr_accuracy))\nprint(\"Test Error of LogisticRegression = %g \" % (1.0 - lr_accuracy))"]},{"cell_type":"markdown","metadata":{},"source":["DecisionTreeClassifier"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+--------+--------------------+\nprediction|Survived|            features|\n+----------+--------+--------------------+\n       0.0|       0|[1.0,19.0,3.0,2.0...|\n       0.0|       0|[1.0,27.0,0.0,2.0...|\n       0.0|       0|(10,[0,1,4,6],[1....|\n       0.0|       0|[1.0,28.0,1.0,0.0...|\n       0.0|       0|(10,[0,1,4,6],[1....|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,3,4,5],[...|\n       0.0|       0|(10,[0,1,6],[1.0,...|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|[1.0,51.0,0.0,1.0...|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,4,6],[2....|\n       1.0|       0|(10,[0,1,4,6],[2....|\n       0.0|       0|(10,[0,1,4,6],[2....|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|(10,[0,1,4,6],[2....|\n+----------+--------+--------------------+\nonly showing top 20 rows\n\nAccuracy of DecisionTreeClassifier is = 0.807018\nTest Error of DecisionTreeClassifier = 0.192982 \n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.ml.classification import DecisionTreeClassifier\ndt = DecisionTreeClassifier(labelCol=\"Survived\", featuresCol=\"features\")\ndt_model = dt.fit(trainingData)\ndt_prediction = dt_model.transform(testData)\ndt_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate how well is DecisionTreeClassifier doing"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of DecisionTreeClassifier is = 0.807018\nTest Error of DecisionTreeClassifier = 0.192982 \n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["dt_accuracy = evaluator.evaluate(dt_prediction)\nprint(\"Accuracy of DecisionTreeClassifier is = %g\"% (dt_accuracy))\nprint(\"Test Error of DecisionTreeClassifier = %g \" % (1.0 - dt_accuracy))\n"]},{"cell_type":"markdown","metadata":{},"source":["RandomForestClassifier"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+--------+--------------------+\nprediction|Survived|            features|\n+----------+--------+--------------------+\n       0.0|       0|[1.0,19.0,3.0,2.0...|\n       0.0|       0|[1.0,27.0,0.0,2.0...|\n       0.0|       0|(10,[0,1,4,6],[1....|\n       0.0|       0|[1.0,28.0,1.0,0.0...|\n       0.0|       0|(10,[0,1,4,6],[1....|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,3,4,5],[...|\n       0.0|       0|(10,[0,1,6],[1.0,...|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|[1.0,51.0,0.0,1.0...|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,4,6],[2....|\n       1.0|       0|(10,[0,1,4,6],[2....|\n       0.0|       0|(10,[0,1,4,6],[2....|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|(10,[0,1,4,6],[2....|\n+----------+--------+--------------------+\nonly showing top 20 rows\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.ml.classification import RandomForestClassifier\nrf = DecisionTreeClassifier(labelCol=\"Survived\", featuresCol=\"features\")\nrf_model = rf.fit(trainingData)\nrf_prediction = rf_model.transform(testData)\nrf_prediction.select(\"prediction\", \"Survived\", \"features\").show()"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate how well is RandomForestClassifier doing"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of RandomForestClassifier is = 0.807018\nTest Error of RandomForestClassifier  = 0.192982 \n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["rf_accuracy = evaluator.evaluate(rf_prediction)\nprint(\"Accuracy of RandomForestClassifier is = %g\"% (rf_accuracy))\nprint(\"Test Error of RandomForestClassifier  = %g \" % (1.0 - rf_accuracy))"]},{"cell_type":"markdown","metadata":{},"source":["Gradient-boosted tree classifier"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+--------+--------------------+\nprediction|Survived|            features|\n+----------+--------+--------------------+\n       0.0|       0|[1.0,19.0,3.0,2.0...|\n       1.0|       0|[1.0,27.0,0.0,2.0...|\n       0.0|       0|(10,[0,1,4,6],[1....|\n       1.0|       0|[1.0,28.0,1.0,0.0...|\n       1.0|       0|(10,[0,1,4,6],[1....|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,3,4,5],[...|\n       0.0|       0|(10,[0,1,6],[1.0,...|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|[1.0,51.0,0.0,1.0...|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,4,6,8],[...|\n       0.0|       0|(10,[0,1,4,6],[2....|\n       0.0|       0|(10,[0,1,4,6],[2....|\n       0.0|       0|(10,[0,1,4,6],[2....|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|(10,[0,1,2,4,5],[...|\n       0.0|       0|(10,[0,1,4,6],[2....|\n+----------+--------+--------------------+\nonly showing top 20 rows\n\nAccuracy of Gradient-boosted tree classifie is = 0.824561\nTest Error of Gradient-boosted tree classifie 0.175439\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.ml.classification import GBTClassifier\ngbt = GBTClassifier(labelCol=\"Survived\", featuresCol=\"features\",maxIter=10)\ngbt_model = gbt.fit(trainingData)\ngbt_prediction = gbt_model.transform(testData)\ngbt_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate how well is Gradient-boosted doing"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of Gradient-boosted tree classifie is = 0.824561\nTest Error of Gradient-boosted tree classifie 0.175439\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["gbt_accuracy = evaluator.evaluate(gbt_prediction)\nprint(\"Accuracy of Gradient-boosted tree classifie is = %g\"% (gbt_accuracy))\nprint(\"Test Error of Gradient-boosted tree classifie %g\"% (1.0 - gbt_accuracy))"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate how well is DecisionTreeClassifier doing"]},{"cell_type":"markdown","metadata":{},"source":["NaiveBayes"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.ml.classification import NaiveBayes\nnb = NaiveBayes(labelCol=\"Survived\", featuresCol=\"features\")\nnb_model = nb.fit(trainingData)\nnb_prediction = nb_model.transform(testData)\nnb_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate how well is NaiveBayes doing"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of NaiveBayes is  = 0.695906\nTest Error of NaiveBayes  = 0.304094 \n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["nb_accuracy = evaluator.evaluate(nb_prediction)\nprint(\"Accuracy of NaiveBayes is  = %g\"% (nb_accuracy))\nprint(\"Test Error of NaiveBayes  = %g \" % (1.0 - nb_accuracy))"]},{"cell_type":"markdown","metadata":{},"source":["Support Vector Machine"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.ml.classification import LinearSVC\nsvm = LinearSVC(labelCol=\"Survived\", featuresCol=\"features\")\nsvm_model = svm.fit(trainingData)\nsvm_prediction = svm_model.transform(testData)\nsvm_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate how well is Support Vector Machine doing"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of Support Vector Machine is = 0.836257\nTest Error of Support Vector Machine = 0.163743 \n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["svm_accuracy = evaluator.evaluate(svm_prediction)\n","print(\"Accuracy of Support Vector Machine is = %g\"% (svm_accuracy))\n","print(\"Test Error of Support Vector Machine = %g \" % (1.0 - svm_accuracy))"]},{"cell_type":"markdown","metadata":{},"source":["How to increase accuracy of a model ?\n  * Add new features or drop existing features and train model\n  * Tune ML algorith (https://spark.apache.org/docs/latest/ml-tuning.html)"]},{"cell_type":"markdown","metadata":{},"source":["### Reference\n\nhttps://spark.apache.org/docs/latest/ml-classification-regression.html"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[],"source":[""]}],"metadata":{"name":"kaggle-titanic-pyspark","notebookId":3865595167034368},"nbformat":4,"nbformat_minor":0}